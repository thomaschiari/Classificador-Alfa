{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import plot_tree\n",
    "from ClassificadorAlfa import ClassificadorAlfa\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'healthcare-dataset-stroke-data.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hipótese 1\n",
    "\n",
    "Para a hipótese 1, vamos testar todos os dados contidos no DataFrame, sem alterações, porém apenas os dados que podem ser tratados como Booleanos. Vamos utilizar as variáveis categóricas para realizar o teste. A hipótese nula, no caso, seria montar um classificador que irá sempre prever os dados como sendo o mais frequente $(x)$, ou seja, será a acurácia medida ao dividir tal valor pelo total dos dados contidos no DataFrame $(N)$:\n",
    "\n",
    "$$\n",
    "Acurácia = \\frac{x}{N}\n",
    "$$\n",
    "\n",
    "Portanto, vamos calcular, ao final, a acurácia da hipótese nula e verificar como a nossa hipótese, utilizando todas as variáveis categóricas, se comporta com relação a ela."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separando target e features\n",
    "try:\n",
    "    df_ = df.drop(['id', 'bmi', 'age', 'avg_glucose_level'], axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "X = df_.drop('stroke', axis=1)\n",
    "y = df_['stroke']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo variáveis categoricas\n",
    "object_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "int_features = [feature for feature in X.columns if X[feature].dtype == 'int64']\n",
    "categorical_features = object_features + int_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo variáveis dummy\n",
    "X = X[categorical_features]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "X.hypertension = X.hypertension.astype('bool')\n",
    "X.heart_disease = X.heart_disease.astype('bool')\n",
    "\n",
    "X_names = X.columns\n",
    "\n",
    "y = y.replace(0,-1)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inicializando os parâmetros do modelo\n",
    "a = np.random.randn(X_train.shape[1], 1)\n",
    "b = 1.0\n",
    "\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "\n",
    "parametros = [a, b, X_train, y_train]\n",
    "learning_rate = 0.0001\n",
    "num_iteracoes = 50000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador = ClassificadorAlfa(learning_rate, num_iteracoes, parametros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "a, b = classificador.treinar()\n",
    "a, b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fazendo previsões\n",
    "ypred = a.T @ X_test.T + b\n",
    "ypred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acuracia = ClassificadorAlfa.acuracia(y_test, ypred)\n",
    "print(f'A acurácia do modelo foi de {acuracia*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecionando as features mais importantes\n",
    "features = X_names\n",
    "importances = pd.DataFrame(data=a, index=features, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo a acurácia da hipótese nula\n",
    "acuracia_nula = y[y == -1].shape[0] / y.shape[0]\n",
    "\n",
    "print(f'A acurácia da hipótese nula foi de {acuracia_nula*100:.2f}%')\n",
    "print(f'A acurácia do modelo foi de {acuracia*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilizando um classificador de árvore de decisão\n",
    "\n",
    "Em seguida, vamos comparar o nosso modelo com um classificador de árvore de decisão, comparando, novamente, as acurácias obtidas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador = DecisionTreeClassifier(criterion='entropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acuracia = classificador.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotando a árvore de decisão\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(30, 30))\n",
    "plot_tree(classificador, filled=True, rounded=True, class_names=['Não teve AVC', 'Teve AVC'], feature_names=X_names, fontsize=15, node_ids=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo as features mais importantes\n",
    "importances = pd.DataFrame(data=classificador.feature_importances_, index=X_names, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'A acurácia da hipótese nula foi de {acuracia_nula*100:.2f}%')\n",
    "print(f'A acurácia do modelo foi de {acuracia*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como podemos observar com as acurácias obtidas, todas ficaram rondando os 95% nos testes. Como a grande maioria dos dados na base são de pessoas que não tiveram AVCs, o classificador da hipótese nula sempre terá uma acurácia muito alta, visto que ele sempre irá prever que a pessoa não teve AVC. Assim, o nosso modelo não funciona de maneira significativamente melhor que a hipótese nula, assim como o modelo de árvore de decisão. Na nossa próxima hipótese, tentaremos realizar o classificador, trabalhando com uma base de dados reduzida, para tentarmos verificar uma mudança mais significativa na acurácia."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hipótese 2\n",
    "\n",
    "Para nossa próxima hipótese, manteremos o cálculo da acurácia da hipótese nula, porém obteremos um subset, dentro de nossa base de dados, com valores balanceados de pessoas com e sem AVCs, ou seja, teremos uma base de dados com 50% de pessoas que tiveram AVCs e 50% de pessoas que não tiveram AVCs. Assim, poderemos verificar se o nosso modelo consegue prever melhor os casos de AVCs, visto que teremos uma base de dados mais balanceada. Nesse caso, a acurácia de nosso classificador nulo será de 50%."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preparando os dados\n",
    "try:\n",
    "    df_ = df.drop(['id', 'bmi', 'age', 'avg_glucose_level'], axis=1)\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separando a base de dados balanceada\n",
    "df_stroke = df_[df_.stroke == 1]\n",
    "df_no_stroke = df_[df_.stroke == 0]\n",
    "# Obtendo um sample aleatório da base de dados sem AVCs\n",
    "df_no_stroke = df_no_stroke.sample(n=df_stroke.shape[0], random_state=42)\n",
    "# Concatenando os dados\n",
    "df_ = pd.concat([df_stroke, df_no_stroke])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separando os dados\n",
    "X = df_.drop('stroke', axis=1)\n",
    "y = df_.stroke"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo variáveis categoricas\n",
    "object_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "int_features = [feature for feature in X.columns if X[feature].dtype == 'int64']\n",
    "categorical_features = object_features + int_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo variáveis dummy\n",
    "X = X[categorical_features]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "X.hypertension = X.hypertension.astype('bool')\n",
    "X.heart_disease = X.heart_disease.astype('bool')\n",
    "\n",
    "X_names = X.columns\n",
    "\n",
    "y = y.replace(0,-1)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inicializando os parâmetros do modelo\n",
    "a = np.random.randn(X_train.shape[1], 1)\n",
    "b = 1.0\n",
    "\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "\n",
    "parametros = [a, b, X_train, y_train]\n",
    "learning_rate = 0.0001\n",
    "num_iteracoes = 50000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador = ClassificadorAlfa(learning_rate, num_iteracoes, parametros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "a, b = classificador.treinar()\n",
    "a, b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fazendo previsões\n",
    "ypred = a.T @ X_test.T + b\n",
    "ypred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acuracia = ClassificadorAlfa.acuracia(y_test, ypred)\n",
    "print(f'A acurácia do modelo foi de {acuracia*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecionando as features mais importantes\n",
    "features = X_names\n",
    "importances = pd.DataFrame(data=a, index=features, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo a acurácia da hipótese nula\n",
    "acuracia_nula = y[y == -1].shape[0] / y.shape[0]\n",
    "\n",
    "print(f'A acurácia da hipótese nula foi de {acuracia_nula*100:.2f}%')\n",
    "print(f'A acurácia do modelo foi de {acuracia*100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilizando um classificador de árvore de decisão\n",
    "\n",
    "Em seguida, vamos comparar o nosso modelo com um classificador de árvore de decisão, comparando, novamente, as acurácias obtidas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador = DecisionTreeClassifier(criterion='entropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acuracia = classificador.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotando a árvore de decisão\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "plot_tree(classificador, filled=True, rounded=True, class_names=['Não teve AVC', 'Teve AVC'], feature_names=X_names,\n",
    "          fontsize=15, node_ids=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo as features mais importantes\n",
    "importances = pd.DataFrame(data=classificador.feature_importances_, index=X_names, columns=['importance']).sort_values(\n",
    "    by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'A acurácia da hipótese nula foi de {acuracia_nula * 100:.2f}%')\n",
    "print(f'A acurácia do modelo foi de {acuracia * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Na nossa segunda hipótese, a diferença entre os modelos e a hipótese nula foi mais significativa. Obtivemos, como descrito anteriormente, uma base de dados balanceada, com 50% dos dados de pessoas que tiveram AVCs e 50% que não o tiveram. Assim, a acurácia nula da base de dados permaneceu em 50%. O modelo `ClassificadorAlfa` obteve uma acurácia de pouco mais de 59%, se tratando de uma diferença mais significativa. O classificador de árvore de decisão manteve uma acurácia de aproximadamente 53%, o que também é uma diferença significativa em relação à hipótese nula, mesmo que não tão significativa quanto a diferença obtida pelo `ClassificadorAlfa`. Em seguida, vamos analisar a nossa terceira hipótese."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hipótese 3\n",
    "\n",
    "Em nossa terceira hipótese, vamos utilizar apenas os dados relacionados à saúde dos indivíduos, desconsiderando fatores como trabalho, casamento e moradia. A ideia é verificar se os dados relacionados à saúde presentes no dataset são suficientes para prever se uma pessoa teve ou não um AVC."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Obtendo os dados\n",
    "try:\n",
    "    df_ = df.drop(['id', 'ever_married', 'work_type', 'Residence_type'], axis=1)\n",
    "except:\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Criando clusters para as variáveis contínuas (clusters obtidos via ChatGPT)\n",
    "df_['age'] = pd.cut(df.age, bins=[0, 13, 20, 40, 60, 100], labels=['Child', 'Teenager', 'Young-adult', 'Middle-aged', 'Elder'])\n",
    "\n",
    "df_['bmi'] = pd.cut(df.bmi, bins=[0, 16.5, 25, 30, 40, 100], labels=['Underweight', 'Normal', 'Overweight', 'Obese', 'Morbidly-obese'])\n",
    "\n",
    "df_['avg_glucose_level'] = pd.cut(df.avg_glucose_level, bins=[0, 90, 120, 140, 180, 280], labels=['Low', 'Normal', 'High-normal', 'Mildly-high', 'Severely-high'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separando a base de dados balanceada\n",
    "df_stroke = df_[df_.stroke == 1]\n",
    "df_no_stroke = df_[df_.stroke == 0]\n",
    "# Obtendo um sample aleatório da base de dados sem AVCs\n",
    "df_no_stroke = df_no_stroke.sample(n=df_stroke.shape[0], random_state=42)\n",
    "# Concatenando os dados\n",
    "df_ = pd.concat([df_stroke, df_no_stroke])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separando os dados\n",
    "X = df_.drop('stroke', axis=1)\n",
    "y = df_.stroke"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo variáveis categoricas\n",
    "object_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "int_features = [feature for feature in X.columns if X[feature].dtype == 'int64']\n",
    "categorical_features = object_features + int_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo variáveis dummy\n",
    "X = X[categorical_features]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "X.hypertension = X.hypertension.astype('bool')\n",
    "X.heart_disease = X.heart_disease.astype('bool')\n",
    "\n",
    "X_names = X.columns\n",
    "\n",
    "y = y.replace(0, -1)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Inicializando os parâmetros do modelo\n",
    "a = np.random.randn(X_train.shape[1], 1)\n",
    "b = 1.0\n",
    "\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "\n",
    "parametros = [a, b, X_train, y_train]\n",
    "learning_rate = 0.0001\n",
    "num_iteracoes = 50000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador = ClassificadorAlfa(learning_rate, num_iteracoes, parametros)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "a, b = classificador.treinar()\n",
    "a, b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Fazendo previsões\n",
    "ypred = a.T @ X_test.T + b\n",
    "ypred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acuracia = ClassificadorAlfa.acuracia(y_test, ypred)\n",
    "print(f'A acurácia do modelo foi de {acuracia * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecionando as features mais importantes\n",
    "features = X_names\n",
    "importances = pd.DataFrame(data=a, index=features, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo a acurácia da hipótese nula\n",
    "acuracia_nula = y[y == -1].shape[0] / y.shape[0]\n",
    "\n",
    "print(f'A acurácia da hipótese nula foi de {acuracia_nula * 100:.2f}%')\n",
    "print(f'A acurácia do modelo foi de {acuracia * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Utilizando o classificador de árvore de decisão"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador = DecisionTreeClassifier(criterion='entropy')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classificador.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "acuracia = classificador.score(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotando a árvore de decisão\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(30, 30))\n",
    "plot_tree(classificador, filled=True, rounded=True, class_names=['Não teve AVC', 'Teve AVC'], feature_names=X_names,\n",
    "          fontsize=15, node_ids=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Obtendo as features mais importantes\n",
    "importances = pd.DataFrame(data=classificador.feature_importances_, index=X_names, columns=['importance']).sort_values(\n",
    "    by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'A acurácia da hipótese nula foi de {acuracia_nula * 100:.2f}%')\n",
    "print(f'A acurácia do modelo foi de {acuracia * 100:.2f}%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nessa análise, obtivemos dados de acurácia semelhantes aos testes anteriores. Isso indica que os dados relacionados à saúde são suficientes para prever se uma pessoa teve ou não um AVC. Ademais, ambos os classificadores mostraram, mesmo que não na mesma ordem, que as variáveis mais importantes para a decisão são as relacionadas à hipertensão, presença de doenças cardíacas e uso de cigarros."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hipótese 4\n",
    "\n",
    "Para finalizar, vamos utilizar apenas as variáveis mais relevantes que foram levantadas por nossos classificadores para realizar as análises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}