{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ClassificadorAlfa import ClassificadorAlfa\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('data', 'healthcare-dataset-stroke-data.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hipotese 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Separando target e features\n",
    "try:\n",
    "    df.drop(['id', 'bmi', 'age', 'avg_glucose_level'], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Obtendo variáveis categoricas\n",
    "object_features = [feature for feature in X.columns if X[feature].dtype == 'O']\n",
    "int_features = [feature for feature in X.columns if X[feature].dtype == 'int64']\n",
    "categorical_features = object_features + int_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Obtendo variáveis dummy\n",
    "X = X[categorical_features]\n",
    "\n",
    "X = pd.get_dummies(X)\n",
    "X.hypertension = X.hypertension.astype('bool')\n",
    "X.heart_disease = X.heart_disease.astype('bool')\n",
    "\n",
    "X_names = X.columns\n",
    "\n",
    "y = y.replace(0,-1)\n",
    "\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.5)\n",
    "X_train = X_train.astype('float64')\n",
    "y_train = y_train.astype('float64')\n",
    "X_test = X_test.astype('float64')\n",
    "y_test = y_test.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Inicializando os parâmetros do modelo\n",
    "a = np.random.randn(X_train.shape[1], 1)\n",
    "b = 1.0\n",
    "\n",
    "X_train = X_train.T\n",
    "y_train = y_train.T\n",
    "\n",
    "parametros = [a, b, X_train, y_train]\n",
    "learning_rate = 0.0001\n",
    "num_iteracoes = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classificador = ClassificadorAlfa(learning_rate, num_iteracoes, parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Treinando o modelo\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m a, b \u001B[38;5;241m=\u001B[39m \u001B[43mclassificador\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtreinar\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m a, b\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/ClassificadorAlfa.py:67\u001B[0m, in \u001B[0;36mClassificadorAlfa.treinar\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtreinar\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m     61\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;124;03m    Treina o modelo para encontrar os melhores valores dos parâmetros.\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;124;03m    \u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    tuple: tupla contendo os valores otimizados dos parâmetros a e b.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 67\u001B[0m     a, b \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmelhorar_modelo\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#otimiza os parâmetros do modelo\u001B[39;00m\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m a, b\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/ClassificadorAlfa.py:55\u001B[0m, in \u001B[0;36mClassificadorAlfa.melhorar_modelo\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     53\u001B[0m a, b, x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparams\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miters):\n\u001B[0;32m---> 55\u001B[0m     g_ \u001B[38;5;241m=\u001B[39m \u001B[43mg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#calcula o gradiente da função erro para os parâmetros atuais\u001B[39;00m\n\u001B[1;32m     56\u001B[0m     a \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearning_rate \u001B[38;5;241m*\u001B[39m g_[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;66;03m#atualiza o valor de a usando o gradiente\u001B[39;00m\n\u001B[1;32m     57\u001B[0m     b \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlearning_rate \u001B[38;5;241m*\u001B[39m g_[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;66;03m#atualiza o valor de b usando o gradiente\u001B[39;00m\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/wrap_util.py:20\u001B[0m, in \u001B[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     19\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(args[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m argnum)\n\u001B[0;32m---> 20\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43munary_operator\u001B[49m\u001B[43m(\u001B[49m\u001B[43munary_f\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnary_op_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnary_op_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/differential_operators.py:28\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(fun, x)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;129m@unary_to_nary\u001B[39m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgrad\u001B[39m(fun, x):\n\u001B[1;32m     23\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;124;03m    Returns a function which computes the gradient of `fun` with respect to\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;124;03m    positional argument number `argnum`. The returned function takes the same\u001B[39;00m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;124;03m    arguments as `fun`, but returns the gradient instead. The function `fun`\u001B[39;00m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;124;03m    should be scalar-valued. The gradient has the same type as the argument.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 28\u001B[0m     vjp, ans \u001B[38;5;241m=\u001B[39m \u001B[43m_make_vjp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vspace(ans)\u001B[38;5;241m.\u001B[39msize \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGrad only applies to real scalar-output functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     31\u001B[0m                         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/core.py:10\u001B[0m, in \u001B[0;36mmake_vjp\u001B[0;34m(fun, x)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_vjp\u001B[39m(fun, x):\n\u001B[1;32m      9\u001B[0m     start_node \u001B[38;5;241m=\u001B[39m VJPNode\u001B[38;5;241m.\u001B[39mnew_root()\n\u001B[0;32m---> 10\u001B[0m     end_value, end_node \u001B[38;5;241m=\u001B[39m  \u001B[43mtrace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_node\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m end_node \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvjp\u001B[39m(g): \u001B[38;5;28;01mreturn\u001B[39;00m vspace(x)\u001B[38;5;241m.\u001B[39mzeros()\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/tracer.py:10\u001B[0m, in \u001B[0;36mtrace\u001B[0;34m(start_node, fun, x)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trace_stack\u001B[38;5;241m.\u001B[39mnew_trace() \u001B[38;5;28;01mas\u001B[39;00m t:\n\u001B[1;32m      9\u001B[0m     start_box \u001B[38;5;241m=\u001B[39m new_box(x, t, start_node)\n\u001B[0;32m---> 10\u001B[0m     end_box \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_box\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m isbox(end_box) \u001B[38;5;129;01mand\u001B[39;00m end_box\u001B[38;5;241m.\u001B[39m_trace \u001B[38;5;241m==\u001B[39m start_box\u001B[38;5;241m.\u001B[39m_trace:\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m end_box\u001B[38;5;241m.\u001B[39m_value, end_box\u001B[38;5;241m.\u001B[39m_node\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/wrap_util.py:15\u001B[0m, in \u001B[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f.<locals>.unary_f\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     14\u001B[0m     subargs \u001B[38;5;241m=\u001B[39m subvals(args, \u001B[38;5;28mzip\u001B[39m(argnum, x))\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msubargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/ClassificadorAlfa.py:41\u001B[0m, in \u001B[0;36mClassificadorAlfa.erro\u001B[0;34m(params)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124;03mCalcula o erro quadrático médio (MSE) do modelo com os parâmetros passados como argumento.\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124;03m\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[38;5;124;03mfloat: valor do MSE calculado.\u001B[39;00m\n\u001B[1;32m     39\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     40\u001B[0m a, b, x, y \u001B[38;5;241m=\u001B[39m params\n\u001B[0;32m---> 41\u001B[0m yhat \u001B[38;5;241m=\u001B[39m \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[38;5;129;43m@x\u001B[39;49m \u001B[38;5;241m+\u001B[39m b \u001B[38;5;66;03m#calcula a predição do modelo para as features x\u001B[39;00m\n\u001B[1;32m     42\u001B[0m mse \u001B[38;5;241m=\u001B[39m np_\u001B[38;5;241m.\u001B[39mmean((yhat \u001B[38;5;241m-\u001B[39m y)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m2\u001B[39m) \u001B[38;5;66;03m#calcula o MSE entre a predição do modelo e os valores reais y\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m mse\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/numpy/numpy_boxes.py:32\u001B[0m, in \u001B[0;36mArrayBox.__matmul__\u001B[0;34m(self, other)\u001B[0m\n\u001B[0;32m---> 32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__matmul__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other): \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43manp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmatmul\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/tracer.py:44\u001B[0m, in \u001B[0;36mprimitive.<locals>.f_wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     42\u001B[0m parents \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(box\u001B[38;5;241m.\u001B[39m_node \u001B[38;5;28;01mfor\u001B[39;00m _     , box \u001B[38;5;129;01min\u001B[39;00m boxed_args)\n\u001B[1;32m     43\u001B[0m argnums \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(argnum    \u001B[38;5;28;01mfor\u001B[39;00m argnum, _   \u001B[38;5;129;01min\u001B[39;00m boxed_args)\n\u001B[0;32m---> 44\u001B[0m ans \u001B[38;5;241m=\u001B[39m \u001B[43mf_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margvals\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m node \u001B[38;5;241m=\u001B[39m node_constructor(ans, f_wrapped, argvals, kwargs, argnums, parents)\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m new_box(ans, trace, node)\n",
      "File \u001B[0;32m~/dev/insper/3sem/alglin/aps6/Classificador-Alfa/env/lib/python3.10/site-packages/autograd/tracer.py:48\u001B[0m, in \u001B[0;36mprimitive.<locals>.f_wrapped\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m new_box(ans, trace, node)\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf_raw\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "a, b = classificador.treinar()\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fazendo previsões\n",
    "ypred = a.T @ X_test.T + b\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acuracia = ClassificadorAlfa.acuracia(y_test, ypred)\n",
    "print(f'A acurácia do modelo foi de {acuracia*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Selecionando as features mais importantes\n",
    "features = X_names\n",
    "importances = pd.DataFrame(data=a, index=features, columns=['importance']).sort_values(by='importance', ascending=False)\n",
    "importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}